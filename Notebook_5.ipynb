{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#start to 2015-11-02 val set\n",
    "#2017-3-15 onwards validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpk\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\vedpk\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\vedpk\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import datetime as dt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_visit =  pd.read_csv('../Input/air_visit_data.csv')\n",
    "air_store =  pd.read_csv('../Input/air_store_info_proc1.csv')\n",
    "hpg_store = pd.read_csv('../Input/hpg_store_info_proc1.csv')\n",
    "air_res = pd.read_csv('../Input/air_reserve.csv')\n",
    "hpg_res =  pd.read_csv('../Input/hpg_reserve.csv')\n",
    "store_id =  pd.read_csv('../Input/store_id_relation.csv')\n",
    "sample_submission =  pd.read_csv('../Input/sample_submission.csv')\n",
    "date_info =  pd.read_csv('../Input/date_info.csv').rename(columns={'calendar_date':'visit_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hpg_res = pd.merge(hpg_res, store_id, how='inner', on=['hpg_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_res['visit_datetime'] = pd.to_datetime(air_res['visit_datetime'])\n",
    "air_res['visit_datetime'] = air_res['visit_datetime'].dt.date\n",
    "air_res['reserve_datetime'] = pd.to_datetime(air_res['reserve_datetime'])\n",
    "air_res['reserve_datetime'] = air_res['reserve_datetime'].dt.date\n",
    "air_res['reserve_datetime_diff'] = air_res.apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "tmp1 = air_res.groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "tmp2 = air_res.groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "air_res = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hpg_res['visit_datetime'] = pd.to_datetime(hpg_res['visit_datetime'])\n",
    "hpg_res['visit_datetime'] = hpg_res['visit_datetime'].dt.date\n",
    "hpg_res['reserve_datetime'] = pd.to_datetime(hpg_res['reserve_datetime'])\n",
    "hpg_res['reserve_datetime'] = hpg_res['reserve_datetime'].dt.date\n",
    "hpg_res['reserve_datetime_diff'] = hpg_res.apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "tmp1 = hpg_res.groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "tmp2 = hpg_res.groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "hpg_res = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_visit['visit_date'] = pd.to_datetime(air_visit['visit_date'])\n",
    "air_visit['dow'] = air_visit['visit_date'].dt.dayofweek\n",
    "air_visit['year'] = air_visit['visit_date'].dt.year\n",
    "air_visit['month'] = air_visit['visit_date'].dt.month\n",
    "air_visit['visit_date'] = air_visit['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission['visit_date'] = sample_submission['id'].map(lambda x: str(x).split('_')[2])\n",
    "sample_submission['air_store_id'] = sample_submission['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "sample_submission['visit_date'] = pd.to_datetime(sample_submission['visit_date'])\n",
    "sample_submission['dow'] = sample_submission['visit_date'].dt.dayofweek\n",
    "sample_submission['year'] = sample_submission['visit_date'].dt.year\n",
    "sample_submission['month'] = sample_submission['visit_date'].dt.month\n",
    "sample_submission['visit_date'] = sample_submission['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_stores = sample_submission['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(477)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_visit.sort_values('visit_date').iloc[-1]['visit_date']-air_visit.sort_values('visit_date').iloc[0]['visit_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2016, 3, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_visit.sort_values('visit_date').iloc[0]['visit_date']+dt.timedelta(days=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2017, 3, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_visit.sort_values('visit_date').iloc[-1]['visit_date']-dt.timedelta(days=38) #38days validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = air_visit[air_visit['visit_date'] < dt.date(2017, 3, 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors  dow  year  month\n",
       "0  air_ba937bf13d40fb24  2016-01-13        25    2  2016      1\n",
       "1  air_ba937bf13d40fb24  2016-01-14        32    3  2016      1\n",
       "2  air_ba937bf13d40fb24  2016-01-15        29    4  2016      1\n",
       "3  air_ba937bf13d40fb24  2016-01-16        22    5  2016      1\n",
       "4  air_ba937bf13d40fb24  2016-01-18         6    0  2016      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_visit = air_visit[air_visit['visit_date'] > dt.date(2016, 3, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sure it can be compressed...\n",
    "tmp = air_visit.groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "tmp = air_visit.groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = air_visit.groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = air_visit.groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = air_visit.groupby(['air_store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores = pd.merge(stores, air_store, how='left', on=['air_store_id']) \n",
    "\n",
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\n",
    "stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for i in range(10):\n",
    "    stores['air_genre_name'+str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    stores['air_area_name'+str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_info['visit_date'] = pd.to_datetime(date_info['visit_date'])\n",
    "date_info['day_of_week'] = lbl.fit_transform(date_info['day_of_week'])\n",
    "date_info['visit_date'] = date_info['visit_date'].dt.date\n",
    "train = pd.merge(air_visit, date_info, how='left', on=['visit_date']) \n",
    "test = pd.merge(sample_submission, date_info, how='left', on=['visit_date']) \n",
    "\n",
    "val = pd.merge(val, date_info, how='left', on=['visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, stores, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(test, stores, how='left', on=['air_store_id','dow'])\n",
    "\n",
    "val = pd.merge(val, stores, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, air_res, how='left', on=['air_store_id','visit_date']) \n",
    "test = pd.merge(test, air_res, how='left', on=['air_store_id','visit_date'])\n",
    "\n",
    "train = pd.merge(train, hpg_res, how='left', on=['air_store_id','visit_date']) \n",
    "test = pd.merge(test, hpg_res, how='left', on=['air_store_id','visit_date'])\n",
    "\n",
    "val = pd.merge(val, air_res, how='left', on=['air_store_id','visit_date']) \n",
    "val = pd.merge(val, hpg_res, how='left', on=['air_store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)\n",
    "val['id'] = val.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val['total_reserv_sum'] = val['rv1_x'] + val['rv1_y']\n",
    "val['total_reserv_mean'] = (val['rv2_x'] + val['rv2_y']) / 2\n",
    "val['total_reserv_dt_diff_mean'] = (val['rs2_x'] + val['rs2_y']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "#test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']\n",
    "\n",
    "#val['date_int'] = val['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "val['var_max_lat'] = val['latitude'].max() - val['latitude']\n",
    "val['var_max_long'] = val['longitude'].max() - val['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']\n",
    "\n",
    "val['lon_plus_lat'] = val['longitude'] + val['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl = preprocessing.LabelEncoder()\n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test['air_store_id2'] = lbl.transform(test['air_store_id'])\n",
    "\n",
    "val['air_store_id2'] = lbl.transform(val['air_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors','prefecture','city']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "val = val.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_b2d8bc9c88b85f96',\n",
       " 'air_cf22e368c1a71d53',\n",
       " 'air_229d7e508d9f1b5e',\n",
       " 'air_d0a7bd3339c3d12a',\n",
       " 'air_cb083b4789a8d3a2',\n",
       " 'air_2703dcb33192b181',\n",
       " 'air_0ead98dd07e7a82a',\n",
       " 'air_d63cfa6d6ab78446']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping stores not in test\n",
    "\n",
    "to_drop = list(set(train['air_store_id']) - set(test['air_store_id']))\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.where(~(train['air_store_id'].isin(to_drop)))\n",
    "train = train.dropna(axis=0,subset=['air_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = val.where(~(val['air_store_id'].isin(to_drop)))\n",
    "val = val.dropna(axis=0,subset=['air_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['air_store_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['objective'] = 'reg:linear'\n",
    "params['booster'] = 'gbtree'\n",
    "params['eval_metric'] = 'rmse'\n",
    "params['eta'] = 0.1\n",
    "params['max_depth'] = 4\n",
    "params['silent'] = 1\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.8\n",
    "params['tree_method'] = \"exact\"\n",
    "\n",
    "#watchlist = [(d_train, 'train'), (d_valid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#X = train[train['visit_date'] < dt.date(2017, 2, 21)]\n",
    "X = train[col]\n",
    "y = train['visitors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.log1p(train['visitors'])\n",
    "X_train = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val = np.log1p(val['visitors'])\n",
    "X_val = val[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(X_train,y_train)\n",
    "d_valid = xgb.DMatrix(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 10\n",
    "kf = model_selection.KFold(n_splits = K, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "[0]\ttrain-rmse:24.3127\tvalid-rmse:0.907521\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.3127\tvalid-rmse:0.907521\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  0 :  20.1819259055\n",
      "RMSLE XGB Regressor, hideout set, fold  0 :  21.5190103397\n",
      "Prediction length on validation set, XGB Regressor, fold  0 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  0 :  222488\n",
      "\n",
      "Fold  1\n",
      "[0]\ttrain-rmse:24.3\tvalid-rmse:0.909273\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.3\tvalid-rmse:0.909273\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  1 :  20.2271118657\n",
      "RMSLE XGB Regressor, hideout set, fold  1 :  21.5411500921\n",
      "Prediction length on validation set, XGB Regressor, fold  1 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  1 :  222488\n",
      "\n",
      "Fold  2\n",
      "[0]\ttrain-rmse:24.3315\tvalid-rmse:0.911056\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.3315\tvalid-rmse:0.911056\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  2 :  20.2245176855\n",
      "RMSLE XGB Regressor, hideout set, fold  2 :  21.5454264018\n",
      "Prediction length on validation set, XGB Regressor, fold  2 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  2 :  222488\n",
      "\n",
      "Fold  3\n",
      "[0]\ttrain-rmse:24.2983\tvalid-rmse:0.906745\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.2983\tvalid-rmse:0.906745\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  3 :  20.1907951242\n",
      "RMSLE XGB Regressor, hideout set, fold  3 :  21.5366329404\n",
      "Prediction length on validation set, XGB Regressor, fold  3 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  3 :  222488\n",
      "\n",
      "Fold  4\n",
      "[0]\ttrain-rmse:24.3022\tvalid-rmse:0.907092\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.3022\tvalid-rmse:0.907092\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  4 :  20.1486038677\n",
      "RMSLE XGB Regressor, hideout set, fold  4 :  21.5417199485\n",
      "Prediction length on validation set, XGB Regressor, fold  4 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  4 :  222488\n",
      "\n",
      "Fold  5\n",
      "[0]\ttrain-rmse:24.2159\tvalid-rmse:0.909553\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.2159\tvalid-rmse:0.909553\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  5 :  20.054283719\n",
      "RMSLE XGB Regressor, hideout set, fold  5 :  21.5374975405\n",
      "Prediction length on validation set, XGB Regressor, fold  5 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  5 :  222488\n",
      "\n",
      "Fold  6\n",
      "[0]\ttrain-rmse:24.3141\tvalid-rmse:0.914361\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.3141\tvalid-rmse:0.914361\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  6 :  20.1150206846\n",
      "RMSLE XGB Regressor, hideout set, fold  6 :  21.5594048825\n",
      "Prediction length on validation set, XGB Regressor, fold  6 :  23541\n",
      "Prediction length on test set, XGB Regressor, fold  6 :  222488\n",
      "\n",
      "Fold  7\n",
      "[0]\ttrain-rmse:24.2864\tvalid-rmse:0.915524\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.2864\tvalid-rmse:0.915524\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  7 :  20.1565003185\n",
      "RMSLE XGB Regressor, hideout set, fold  7 :  21.5780479622\n",
      "Prediction length on validation set, XGB Regressor, fold  7 :  23541\n",
      "Prediction length on test set, XGB Regressor, fold  7 :  222488\n",
      "\n",
      "Fold  8\n",
      "[0]\ttrain-rmse:24.2548\tvalid-rmse:0.91358\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.2548\tvalid-rmse:0.91358\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  8 :  20.2798660648\n",
      "RMSLE XGB Regressor, hideout set, fold  8 :  21.5957454529\n",
      "Prediction length on validation set, XGB Regressor, fold  8 :  23541\n",
      "Prediction length on test set, XGB Regressor, fold  8 :  222488\n",
      "\n",
      "Fold  9\n",
      "[0]\ttrain-rmse:24.2515\tvalid-rmse:0.915298\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.2515\tvalid-rmse:0.915298\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  9 :  20.3957866237\n",
      "RMSLE XGB Regressor, hideout set, fold  9 :  21.5752448572\n",
      "Prediction length on validation set, XGB Regressor, fold  9 :  23541\n",
      "Prediction length on test set, XGB Regressor, fold  9 :  222488\n",
      "\n",
      "Fold  0\n",
      "[0]\ttrain-rmse:24.3447\tvalid-rmse:0.907653\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.3447\tvalid-rmse:0.907653\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  0 :  20.2321377024\n",
      "RMSLE XGB Regressor, hideout set, fold  0 :  21.5570746119\n",
      "Prediction length on validation set, XGB Regressor, fold  0 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  0 :  222488\n",
      "\n",
      "Fold  1\n",
      "[0]\ttrain-rmse:24.2706\tvalid-rmse:0.908963\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.2706\tvalid-rmse:0.908963\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  1 :  20.3404997824\n",
      "RMSLE XGB Regressor, hideout set, fold  1 :  21.5503814101\n",
      "Prediction length on validation set, XGB Regressor, fold  1 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  1 :  222488\n",
      "\n",
      "Fold  2\n",
      "[0]\ttrain-rmse:24.2272\tvalid-rmse:0.910955\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.2272\tvalid-rmse:0.910955\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  2 :  20.1951529717\n",
      "RMSLE XGB Regressor, hideout set, fold  2 :  21.507394922\n",
      "Prediction length on validation set, XGB Regressor, fold  2 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  2 :  222488\n",
      "\n",
      "Fold  3\n",
      "[0]\ttrain-rmse:24.3315\tvalid-rmse:0.908344\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.3315\tvalid-rmse:0.908344\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  3 :  20.1180844261\n",
      "RMSLE XGB Regressor, hideout set, fold  3 :  21.5568952416\n",
      "Prediction length on validation set, XGB Regressor, fold  3 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  3 :  222488\n",
      "\n",
      "Fold  4\n",
      "[0]\ttrain-rmse:24.2207\tvalid-rmse:0.908178\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.2207\tvalid-rmse:0.908178\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  4 :  20.372447369\n",
      "RMSLE XGB Regressor, hideout set, fold  4 :  21.5169781728\n",
      "Prediction length on validation set, XGB Regressor, fold  4 :  23542\n",
      "Prediction length on test set, XGB Regressor, fold  4 :  222488\n",
      "\n",
      "Fold  5\n",
      "[0]\ttrain-rmse:24.2361\tvalid-rmse:0.909585\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.2361\tvalid-rmse:0.909585\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  5 :  20.1832220667\n",
      "RMSLE XGB Regressor, hideout set, fold  5 :  21.5165039359\n",
      "Prediction length on validation set, XGB Regressor, fold  5 :  23542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction length on test set, XGB Regressor, fold  5 :  222488\n",
      "\n",
      "Fold  6\n",
      "[0]\ttrain-rmse:24.3315\tvalid-rmse:0.916378\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.3315\tvalid-rmse:0.916378\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  6 :  20.0449242304\n",
      "RMSLE XGB Regressor, hideout set, fold  6 :  21.5493742065\n",
      "Prediction length on validation set, XGB Regressor, fold  6 :  23541\n",
      "Prediction length on test set, XGB Regressor, fold  6 :  222488\n",
      "\n",
      "Fold  7\n",
      "[0]\ttrain-rmse:24.3058\tvalid-rmse:0.916603\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.3058\tvalid-rmse:0.916603\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  7 :  20.0804548978\n",
      "RMSLE XGB Regressor, hideout set, fold  7 :  21.567385704\n",
      "Prediction length on validation set, XGB Regressor, fold  7 :  23541\n",
      "Prediction length on test set, XGB Regressor, fold  7 :  222488\n",
      "\n",
      "Fold  8\n",
      "[0]\ttrain-rmse:24.3126\tvalid-rmse:0.91249\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.3126\tvalid-rmse:0.91249\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  8 :  20.0446757027\n",
      "RMSLE XGB Regressor, hideout set, fold  8 :  21.5767679285\n",
      "Prediction length on validation set, XGB Regressor, fold  8 :  23541\n",
      "Prediction length on test set, XGB Regressor, fold  8 :  222488\n",
      "\n",
      "Fold  9\n",
      "[0]\ttrain-rmse:24.2834\tvalid-rmse:0.914471\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-rmse:24.2834\tvalid-rmse:0.914471\n",
      "\n",
      "RMSLE XGB Regressor, validation set, fold  9 :  20.3033196971\n",
      "RMSLE XGB Regressor, hideout set, fold  9 :  21.5746609077\n",
      "Prediction length on validation set, XGB Regressor, fold  9 :  23541\n",
      "Prediction length on test set, XGB Regressor, fold  9 :  222488\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = 0\n",
    "#K-Fold Validation for xgboost\n",
    "for a in range(2):\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        # Create data for this fold\n",
    "        y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "        X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :].copy()\n",
    "        #X_test = test[col]\n",
    "        print(\"\\nFold \", i)\n",
    "\n",
    "        d_train = xgb.DMatrix(X_train,y_train)\n",
    "        d_valid = xgb.DMatrix(X_val, y_val)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "        model = (xgb.train(params,d_train,num_boost_round=2000,evals=watchlist,\n",
    "                       early_stopping_rounds=25,verbose_eval=50))\n",
    "        pred = model.predict(xgb.DMatrix(X_valid[col]))\n",
    "        print('RMSLE XGB Regressor, validation set, fold ', i, ': ', RMSLE(np.log1p(y_valid).values, pred))\n",
    "\n",
    "        pred_hideout = model.predict(xgb.DMatrix(X_val))\n",
    "        print('RMSLE XGB Regressor, hideout set, fold ', i, ': ', RMSLE(np.log1p(y_val).values, pred_hideout))\n",
    "        print('Prediction length on validation set, XGB Regressor, fold ', i, ': ', len(pred))\n",
    "        # Accumulate test set predictions\n",
    "\n",
    "        pred = model.predict(xgb.DMatrix(X_val))\n",
    "        print('Prediction length on test set, XGB Regressor, fold ', i, ': ', len(pred))\n",
    "        y_test_pred += pred\n",
    "\n",
    "        del X_train, X_valid, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred /= (2*K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE XGB Regressor, full validtion, fold  9 :  20.0691785942\n"
     ]
    }
   ],
   "source": [
    "print('RMSLE XGB Regressor, full validtion, fold ', i, ': ', RMSLE(np.log1p(val['visitors']).values, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model1 = ensemble.GradientBoostingRegressor(learning_rate=0.2, random_state=3, n_estimators=200, subsample=0.8, \n",
    "                      max_depth =10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model2 = neighbors.KNeighborsRegressor(n_jobs=-1, n_neighbors=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model3 = xgb.XGBRegressor(learning_rate=0.2, random_state=3, n_estimators=200, subsample=0.8, \n",
    "                     colsample_bytree=0.8, max_depth =10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d_train = xgb.DMatrix(X_train,y_train)\n",
    "d_valid = xgb.DMatrix(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model1.fit(train[col], np.log1p(train['visitors'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model2.fit(train[col], np.log1p(train['visitors'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model3.fit(X_train[col], np.log1p(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model4 = (xgb.train(params,d_train,num_boost_round=2000,evals=watchlist,\n",
    "                   early_stopping_rounds=100,verbose_eval=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "preds1 = model1.predict(val[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "preds2 = model2.predict(val[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "preds3 = model3.predict(val[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pred4 = model4.predict(xgb.DMatrix(val[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('RMSE GradientBoostingRegressor: ', RMSLE(np.log1p(val['visitors'].values), preds1))\n",
    "print('RMSE KNeighborsRegressor: ', RMSLE(np.log1p(val['visitors'].values), preds2))\n",
    "print('RMSE XGBRegressor: ', RMSLE(np.log1p(val['visitors'].values), preds3))\n",
    "print('RMSE XGBTrain: ', RMSLE(np.log1p(val['visitors'].values), pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "preds1 = model1.predict(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "preds2 = model2.predict(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "preds3 = model3.predict(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pred4 = model4.predict(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#test['visitors'] = (preds2+preds3) / 2 #(preds1+preds2+preds3) / 3\n",
    "test['visitors'] = (preds1+preds2+preds3+preds4) / 4 \n",
    "test['visitors'] = np.expm1(test['visitors']).clip(lower=0.)\n",
    "sub1 = test[['id','visitors']].copy()\n",
    "#del train; del data;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
